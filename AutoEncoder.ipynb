{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoEncoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNI/1ii6aSV1iDSkK00nFZz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BelemoualemChaimae/Diagnostic-of-diabete-/blob/main/AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnEygDmU7jg7",
        "outputId": "636e9788-5146-4dea-dd55-f8564863c04a"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "# define model\n",
        "model = LogisticRegression()\n",
        "# fit model on training set\n",
        "model.fit(X_train, y_train)\n",
        "# make prediction on test set\n",
        "yhat = model.predict(X_test)\n",
        "# calculate accuracy\n",
        "acc = accuracy_score(y_test, yhat)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8939393939393939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vei_GMwt8K6p",
        "outputId": "7cbf7e5c-8802-4f79-b33b-ff0c15e4d6a8"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "# load the model from file\n",
        "encoder = load_model('encoder.h5')\n",
        "# encode the train data\n",
        "X_train_encode = encoder.predict(X_train)\n",
        "# encode the test data\n",
        "X_test_encode = encoder.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p6fSEHZ8Yxh",
        "outputId": "3ae7baf0-98ac-4245-c1b7-a6d0d8298d50"
      },
      "source": [
        "X_train_encode.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(670, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38YhCZ0C86e_",
        "outputId": "520f8227-f020-4a8e-d309-370d8c1b0d97"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(670, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS2f9TjQ8-kc",
        "outputId": "82eca47e-753d-4bad-aa41-c263a12b310a"
      },
      "source": [
        "# define the model\n",
        "model = LogisticRegression()\n",
        "# fit the model on the training set\n",
        "model.fit(X_train_encode, y_train)\n",
        "# make predictions on the test set\n",
        "yhat = model.predict(X_test_encode)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrk3SeGo9GN1",
        "outputId": "7b41d3e4-634e-4439-f499-235bd6be164b"
      },
      "source": [
        "acc = accuracy_score(y_test, yhat)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9212121212121213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oi8trYuC7AB5",
        "outputId": "7e2c17d8-b208-4b6c-9307-8986fdc6e0e0"
      },
      "source": [
        "# train autoencoder for classification with with compression in the bottleneck layer\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from matplotlib import pyplot\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=100, n_informative=10, n_redundant=90, random_state=1)\n",
        "# number of input columns\n",
        "n_inputs = X.shape[1]\n",
        "# split into train test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# scale data\n",
        "t = MinMaxScaler()\n",
        "t.fit(X_train)\n",
        "X_train = t.transform(X_train)\n",
        "X_test = t.transform(X_test)\n",
        "# define encoder\n",
        "visible = Input(shape=(n_inputs,))\n",
        "# encoder level 1\n",
        "e = Dense(n_inputs*2)(visible)\n",
        "e = LeakyReLU()(e)\n",
        "# encoder level 2\n",
        "e = Dense(n_inputs)(e)\n",
        "e = LeakyReLU()(e)\n",
        "# bottleneck\n",
        "n_bottleneck = round(float(n_inputs) / 2.0)\n",
        "bottleneck = Dense(n_bottleneck)(e)\n",
        "# define decoder, level 1\n",
        "d = Dense(n_inputs)(bottleneck)\n",
        "d = LeakyReLU()(d)\n",
        "# decoder level 2\n",
        "d = Dense(n_inputs*2)(d)\n",
        "d = LeakyReLU()(d)\n",
        "# output layer\n",
        "output = Dense(n_inputs, activation='linear')(d)\n",
        "# define autoencoder model\n",
        "model = Model(inputs=visible, outputs=output)\n",
        "# compile autoencoder model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# plot the autoencoder\n",
        "plot_model(model, 'autoencoder_compress.png', show_shapes=True)\n",
        "# fit the autoencoder model to reconstruct input\n",
        "history = model.fit(X_train, X_train, epochs=200, batch_size=16, verbose=2, validation_data=(X_test,X_test))\n",
        "# plot loss\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "# define an encoder model (without the decoder)\n",
        "encoder = Model(inputs=visible, outputs=bottleneck)\n",
        "plot_model(encoder, 'encoder_compress.png', show_shapes=True)\n",
        "# save the encoder to file\n",
        "encoder.save('encoder.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "42/42 - 1s - loss: 0.0488 - val_loss: 0.0178\n",
            "Epoch 2/200\n",
            "42/42 - 0s - loss: 0.0138 - val_loss: 0.0089\n",
            "Epoch 3/200\n",
            "42/42 - 0s - loss: 0.0061 - val_loss: 0.0035\n",
            "Epoch 4/200\n",
            "42/42 - 0s - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 5/200\n",
            "42/42 - 0s - loss: 0.0013 - val_loss: 9.4879e-04\n",
            "Epoch 6/200\n",
            "42/42 - 0s - loss: 7.7083e-04 - val_loss: 8.5166e-04\n",
            "Epoch 7/200\n",
            "42/42 - 0s - loss: 4.3938e-04 - val_loss: 3.0825e-04\n",
            "Epoch 8/200\n",
            "42/42 - 0s - loss: 2.8207e-04 - val_loss: 2.0761e-04\n",
            "Epoch 9/200\n",
            "42/42 - 0s - loss: 1.6952e-04 - val_loss: 1.5217e-04\n",
            "Epoch 10/200\n",
            "42/42 - 0s - loss: 1.1289e-04 - val_loss: 8.0852e-05\n",
            "Epoch 11/200\n",
            "42/42 - 0s - loss: 1.1106e-04 - val_loss: 8.0621e-05\n",
            "Epoch 12/200\n",
            "42/42 - 0s - loss: 8.5400e-05 - val_loss: 7.1752e-05\n",
            "Epoch 13/200\n",
            "42/42 - 0s - loss: 8.3979e-05 - val_loss: 6.7595e-05\n",
            "Epoch 14/200\n",
            "42/42 - 0s - loss: 5.9666e-05 - val_loss: 8.0964e-05\n",
            "Epoch 15/200\n",
            "42/42 - 0s - loss: 9.6837e-05 - val_loss: 1.1553e-04\n",
            "Epoch 16/200\n",
            "42/42 - 0s - loss: 9.3596e-05 - val_loss: 8.6543e-05\n",
            "Epoch 17/200\n",
            "42/42 - 0s - loss: 1.2624e-04 - val_loss: 4.6104e-05\n",
            "Epoch 18/200\n",
            "42/42 - 0s - loss: 1.2613e-04 - val_loss: 7.1234e-05\n",
            "Epoch 19/200\n",
            "42/42 - 0s - loss: 6.7318e-05 - val_loss: 1.1778e-04\n",
            "Epoch 20/200\n",
            "42/42 - 0s - loss: 7.8390e-05 - val_loss: 1.0199e-04\n",
            "Epoch 21/200\n",
            "42/42 - 0s - loss: 8.7316e-05 - val_loss: 1.0933e-04\n",
            "Epoch 22/200\n",
            "42/42 - 0s - loss: 4.6849e-05 - val_loss: 9.8140e-05\n",
            "Epoch 23/200\n",
            "42/42 - 0s - loss: 4.8647e-05 - val_loss: 3.8993e-05\n",
            "Epoch 24/200\n",
            "42/42 - 0s - loss: 1.9252e-04 - val_loss: 1.1424e-04\n",
            "Epoch 25/200\n",
            "42/42 - 0s - loss: 1.2547e-04 - val_loss: 8.4711e-05\n",
            "Epoch 26/200\n",
            "42/42 - 0s - loss: 7.9806e-05 - val_loss: 6.9575e-05\n",
            "Epoch 27/200\n",
            "42/42 - 0s - loss: 4.3316e-05 - val_loss: 4.5881e-05\n",
            "Epoch 28/200\n",
            "42/42 - 0s - loss: 4.6278e-05 - val_loss: 7.1091e-05\n",
            "Epoch 29/200\n",
            "42/42 - 0s - loss: 5.6028e-05 - val_loss: 1.8383e-04\n",
            "Epoch 30/200\n",
            "42/42 - 0s - loss: 1.0505e-04 - val_loss: 7.5418e-05\n",
            "Epoch 31/200\n",
            "42/42 - 0s - loss: 1.0006e-04 - val_loss: 5.2906e-05\n",
            "Epoch 32/200\n",
            "42/42 - 0s - loss: 7.3777e-05 - val_loss: 8.8348e-05\n",
            "Epoch 33/200\n",
            "42/42 - 0s - loss: 7.7199e-05 - val_loss: 7.7844e-05\n",
            "Epoch 34/200\n",
            "42/42 - 0s - loss: 9.9268e-05 - val_loss: 7.4444e-05\n",
            "Epoch 35/200\n",
            "42/42 - 0s - loss: 6.7568e-05 - val_loss: 4.7412e-05\n",
            "Epoch 36/200\n",
            "42/42 - 0s - loss: 4.6233e-05 - val_loss: 4.8846e-05\n",
            "Epoch 37/200\n",
            "42/42 - 0s - loss: 5.1846e-05 - val_loss: 3.7470e-05\n",
            "Epoch 38/200\n",
            "42/42 - 0s - loss: 5.5388e-05 - val_loss: 4.6155e-05\n",
            "Epoch 39/200\n",
            "42/42 - 0s - loss: 7.9283e-05 - val_loss: 1.6698e-04\n",
            "Epoch 40/200\n",
            "42/42 - 0s - loss: 9.0662e-05 - val_loss: 2.1706e-04\n",
            "Epoch 41/200\n",
            "42/42 - 0s - loss: 1.3965e-04 - val_loss: 9.3825e-05\n",
            "Epoch 42/200\n",
            "42/42 - 0s - loss: 9.8287e-05 - val_loss: 2.1864e-04\n",
            "Epoch 43/200\n",
            "42/42 - 0s - loss: 8.9022e-05 - val_loss: 1.7563e-04\n",
            "Epoch 44/200\n",
            "42/42 - 0s - loss: 1.1352e-04 - val_loss: 2.0573e-04\n",
            "Epoch 45/200\n",
            "42/42 - 0s - loss: 1.5399e-04 - val_loss: 1.5192e-04\n",
            "Epoch 46/200\n",
            "42/42 - 0s - loss: 5.7545e-05 - val_loss: 5.8035e-05\n",
            "Epoch 47/200\n",
            "42/42 - 0s - loss: 3.9453e-05 - val_loss: 2.6653e-05\n",
            "Epoch 48/200\n",
            "42/42 - 0s - loss: 4.2213e-05 - val_loss: 5.1817e-05\n",
            "Epoch 49/200\n",
            "42/42 - 0s - loss: 8.1866e-05 - val_loss: 5.1471e-05\n",
            "Epoch 50/200\n",
            "42/42 - 0s - loss: 8.0441e-05 - val_loss: 8.8641e-05\n",
            "Epoch 51/200\n",
            "42/42 - 0s - loss: 1.0628e-04 - val_loss: 1.7571e-04\n",
            "Epoch 52/200\n",
            "42/42 - 0s - loss: 1.1244e-04 - val_loss: 7.9606e-05\n",
            "Epoch 53/200\n",
            "42/42 - 0s - loss: 7.8053e-05 - val_loss: 1.3062e-04\n",
            "Epoch 54/200\n",
            "42/42 - 0s - loss: 7.9549e-05 - val_loss: 6.5159e-05\n",
            "Epoch 55/200\n",
            "42/42 - 0s - loss: 4.6544e-05 - val_loss: 3.4146e-05\n",
            "Epoch 56/200\n",
            "42/42 - 0s - loss: 1.3011e-04 - val_loss: 3.0799e-04\n",
            "Epoch 57/200\n",
            "42/42 - 0s - loss: 7.8807e-05 - val_loss: 1.7578e-04\n",
            "Epoch 58/200\n",
            "42/42 - 0s - loss: 1.5316e-04 - val_loss: 1.2563e-04\n",
            "Epoch 59/200\n",
            "42/42 - 0s - loss: 5.4683e-05 - val_loss: 4.7033e-05\n",
            "Epoch 60/200\n",
            "42/42 - 0s - loss: 5.2437e-05 - val_loss: 8.7593e-05\n",
            "Epoch 61/200\n",
            "42/42 - 0s - loss: 7.0833e-05 - val_loss: 3.4316e-05\n",
            "Epoch 62/200\n",
            "42/42 - 0s - loss: 4.6013e-05 - val_loss: 5.2627e-05\n",
            "Epoch 63/200\n",
            "42/42 - 0s - loss: 6.4500e-05 - val_loss: 2.4113e-04\n",
            "Epoch 64/200\n",
            "42/42 - 0s - loss: 1.9351e-04 - val_loss: 2.2366e-04\n",
            "Epoch 65/200\n",
            "42/42 - 0s - loss: 1.3511e-04 - val_loss: 1.9118e-04\n",
            "Epoch 66/200\n",
            "42/42 - 0s - loss: 9.8412e-05 - val_loss: 1.0056e-04\n",
            "Epoch 67/200\n",
            "42/42 - 0s - loss: 7.2595e-05 - val_loss: 3.6742e-04\n",
            "Epoch 68/200\n",
            "42/42 - 0s - loss: 1.1836e-04 - val_loss: 1.6425e-04\n",
            "Epoch 69/200\n",
            "42/42 - 0s - loss: 7.1594e-05 - val_loss: 4.0743e-05\n",
            "Epoch 70/200\n",
            "42/42 - 0s - loss: 4.8413e-05 - val_loss: 1.3029e-04\n",
            "Epoch 71/200\n",
            "42/42 - 0s - loss: 1.1283e-04 - val_loss: 1.0585e-04\n",
            "Epoch 72/200\n",
            "42/42 - 0s - loss: 9.2361e-05 - val_loss: 1.0481e-04\n",
            "Epoch 73/200\n",
            "42/42 - 0s - loss: 6.6072e-05 - val_loss: 5.8185e-05\n",
            "Epoch 74/200\n",
            "42/42 - 0s - loss: 1.1417e-04 - val_loss: 6.7882e-05\n",
            "Epoch 75/200\n",
            "42/42 - 0s - loss: 5.1764e-05 - val_loss: 7.0720e-05\n",
            "Epoch 76/200\n",
            "42/42 - 0s - loss: 1.3479e-04 - val_loss: 1.4792e-04\n",
            "Epoch 77/200\n",
            "42/42 - 0s - loss: 8.0857e-05 - val_loss: 1.3321e-04\n",
            "Epoch 78/200\n",
            "42/42 - 0s - loss: 1.2008e-04 - val_loss: 6.1963e-05\n",
            "Epoch 79/200\n",
            "42/42 - 0s - loss: 9.0170e-05 - val_loss: 9.0167e-05\n",
            "Epoch 80/200\n",
            "42/42 - 0s - loss: 3.2800e-05 - val_loss: 4.3579e-05\n",
            "Epoch 81/200\n",
            "42/42 - 0s - loss: 2.1874e-05 - val_loss: 3.3103e-05\n",
            "Epoch 82/200\n",
            "42/42 - 0s - loss: 5.3847e-05 - val_loss: 2.4667e-04\n",
            "Epoch 83/200\n",
            "42/42 - 0s - loss: 1.7730e-04 - val_loss: 9.5279e-05\n",
            "Epoch 84/200\n",
            "42/42 - 0s - loss: 9.0489e-05 - val_loss: 5.3406e-05\n",
            "Epoch 85/200\n",
            "42/42 - 0s - loss: 6.5311e-05 - val_loss: 6.5409e-05\n",
            "Epoch 86/200\n",
            "42/42 - 0s - loss: 3.0366e-05 - val_loss: 4.6244e-05\n",
            "Epoch 87/200\n",
            "42/42 - 0s - loss: 4.4284e-05 - val_loss: 1.2850e-04\n",
            "Epoch 88/200\n",
            "42/42 - 0s - loss: 1.3701e-04 - val_loss: 1.2846e-04\n",
            "Epoch 89/200\n",
            "42/42 - 0s - loss: 1.2515e-04 - val_loss: 1.6406e-04\n",
            "Epoch 90/200\n",
            "42/42 - 0s - loss: 8.3892e-05 - val_loss: 6.3617e-05\n",
            "Epoch 91/200\n",
            "42/42 - 0s - loss: 6.4914e-05 - val_loss: 1.1062e-04\n",
            "Epoch 92/200\n",
            "42/42 - 0s - loss: 6.6506e-05 - val_loss: 4.1264e-05\n",
            "Epoch 93/200\n",
            "42/42 - 0s - loss: 1.3212e-04 - val_loss: 4.1994e-04\n",
            "Epoch 94/200\n",
            "42/42 - 0s - loss: 2.1914e-04 - val_loss: 1.8127e-04\n",
            "Epoch 95/200\n",
            "42/42 - 0s - loss: 1.0096e-04 - val_loss: 5.6555e-05\n",
            "Epoch 96/200\n",
            "42/42 - 0s - loss: 4.0252e-05 - val_loss: 4.5509e-05\n",
            "Epoch 97/200\n",
            "42/42 - 0s - loss: 2.4388e-05 - val_loss: 4.4458e-05\n",
            "Epoch 98/200\n",
            "42/42 - 0s - loss: 3.6684e-05 - val_loss: 5.3320e-05\n",
            "Epoch 99/200\n",
            "42/42 - 0s - loss: 6.3498e-05 - val_loss: 4.5370e-05\n",
            "Epoch 100/200\n",
            "42/42 - 0s - loss: 1.5163e-04 - val_loss: 1.3616e-04\n",
            "Epoch 101/200\n",
            "42/42 - 0s - loss: 9.2320e-05 - val_loss: 9.4283e-05\n",
            "Epoch 102/200\n",
            "42/42 - 0s - loss: 5.1732e-05 - val_loss: 8.7675e-05\n",
            "Epoch 103/200\n",
            "42/42 - 0s - loss: 5.7256e-05 - val_loss: 4.0777e-05\n",
            "Epoch 104/200\n",
            "42/42 - 0s - loss: 6.1388e-05 - val_loss: 1.3346e-04\n",
            "Epoch 105/200\n",
            "42/42 - 0s - loss: 1.4660e-04 - val_loss: 3.1058e-04\n",
            "Epoch 106/200\n",
            "42/42 - 0s - loss: 3.2676e-04 - val_loss: 2.9387e-04\n",
            "Epoch 107/200\n",
            "42/42 - 0s - loss: 9.9551e-05 - val_loss: 7.7261e-05\n",
            "Epoch 108/200\n",
            "42/42 - 0s - loss: 3.8030e-05 - val_loss: 3.8574e-05\n",
            "Epoch 109/200\n",
            "42/42 - 0s - loss: 2.3883e-05 - val_loss: 4.4355e-05\n",
            "Epoch 110/200\n",
            "42/42 - 0s - loss: 3.9430e-05 - val_loss: 9.8286e-05\n",
            "Epoch 111/200\n",
            "42/42 - 0s - loss: 6.7642e-05 - val_loss: 4.3593e-05\n",
            "Epoch 112/200\n",
            "42/42 - 0s - loss: 3.3184e-05 - val_loss: 4.6864e-05\n",
            "Epoch 113/200\n",
            "42/42 - 0s - loss: 5.7570e-05 - val_loss: 8.9119e-05\n",
            "Epoch 114/200\n",
            "42/42 - 0s - loss: 8.5435e-05 - val_loss: 6.8135e-05\n",
            "Epoch 115/200\n",
            "42/42 - 0s - loss: 4.9054e-05 - val_loss: 1.4038e-04\n",
            "Epoch 116/200\n",
            "42/42 - 0s - loss: 1.0654e-04 - val_loss: 7.7355e-05\n",
            "Epoch 117/200\n",
            "42/42 - 0s - loss: 7.1664e-05 - val_loss: 9.9328e-05\n",
            "Epoch 118/200\n",
            "42/42 - 0s - loss: 1.4004e-04 - val_loss: 1.2674e-04\n",
            "Epoch 119/200\n",
            "42/42 - 0s - loss: 9.8753e-05 - val_loss: 7.1915e-05\n",
            "Epoch 120/200\n",
            "42/42 - 0s - loss: 4.9926e-05 - val_loss: 5.9210e-05\n",
            "Epoch 121/200\n",
            "42/42 - 0s - loss: 6.9639e-05 - val_loss: 9.5903e-05\n",
            "Epoch 122/200\n",
            "42/42 - 0s - loss: 1.4689e-04 - val_loss: 6.4750e-05\n",
            "Epoch 123/200\n",
            "42/42 - 0s - loss: 3.9314e-05 - val_loss: 3.7223e-05\n",
            "Epoch 124/200\n",
            "42/42 - 0s - loss: 3.1083e-05 - val_loss: 4.1326e-05\n",
            "Epoch 125/200\n",
            "42/42 - 0s - loss: 5.1864e-05 - val_loss: 4.7431e-05\n",
            "Epoch 126/200\n",
            "42/42 - 0s - loss: 3.8351e-05 - val_loss: 4.9102e-05\n",
            "Epoch 127/200\n",
            "42/42 - 0s - loss: 9.0362e-05 - val_loss: 1.5444e-04\n",
            "Epoch 128/200\n",
            "42/42 - 0s - loss: 9.5007e-05 - val_loss: 6.3944e-05\n",
            "Epoch 129/200\n",
            "42/42 - 0s - loss: 8.8122e-05 - val_loss: 1.6161e-04\n",
            "Epoch 130/200\n",
            "42/42 - 0s - loss: 1.4785e-04 - val_loss: 7.3700e-05\n",
            "Epoch 131/200\n",
            "42/42 - 0s - loss: 9.2368e-05 - val_loss: 2.0126e-04\n",
            "Epoch 132/200\n",
            "42/42 - 0s - loss: 1.0107e-04 - val_loss: 8.9727e-05\n",
            "Epoch 133/200\n",
            "42/42 - 0s - loss: 4.5102e-05 - val_loss: 4.7436e-05\n",
            "Epoch 134/200\n",
            "42/42 - 0s - loss: 2.4120e-05 - val_loss: 3.9823e-05\n",
            "Epoch 135/200\n",
            "42/42 - 0s - loss: 2.0357e-05 - val_loss: 3.1340e-05\n",
            "Epoch 136/200\n",
            "42/42 - 0s - loss: 2.6816e-05 - val_loss: 5.8871e-05\n",
            "Epoch 137/200\n",
            "42/42 - 0s - loss: 1.1058e-04 - val_loss: 1.2630e-04\n",
            "Epoch 138/200\n",
            "42/42 - 0s - loss: 1.3632e-04 - val_loss: 1.8139e-04\n",
            "Epoch 139/200\n",
            "42/42 - 0s - loss: 1.1379e-04 - val_loss: 7.9151e-05\n",
            "Epoch 140/200\n",
            "42/42 - 0s - loss: 5.2473e-05 - val_loss: 8.8329e-05\n",
            "Epoch 141/200\n",
            "42/42 - 0s - loss: 4.0925e-05 - val_loss: 1.0291e-04\n",
            "Epoch 142/200\n",
            "42/42 - 0s - loss: 1.1049e-04 - val_loss: 2.8037e-04\n",
            "Epoch 143/200\n",
            "42/42 - 0s - loss: 1.9584e-04 - val_loss: 7.4569e-05\n",
            "Epoch 144/200\n",
            "42/42 - 0s - loss: 5.4568e-05 - val_loss: 5.6612e-05\n",
            "Epoch 145/200\n",
            "42/42 - 0s - loss: 3.9558e-05 - val_loss: 6.5289e-05\n",
            "Epoch 146/200\n",
            "42/42 - 0s - loss: 5.6711e-05 - val_loss: 9.5693e-05\n",
            "Epoch 147/200\n",
            "42/42 - 0s - loss: 6.4132e-05 - val_loss: 8.3734e-05\n",
            "Epoch 148/200\n",
            "42/42 - 0s - loss: 4.6654e-05 - val_loss: 3.8520e-05\n",
            "Epoch 149/200\n",
            "42/42 - 0s - loss: 1.9009e-05 - val_loss: 3.8973e-05\n",
            "Epoch 150/200\n",
            "42/42 - 0s - loss: 6.3081e-05 - val_loss: 3.8870e-05\n",
            "Epoch 151/200\n",
            "42/42 - 0s - loss: 3.7256e-05 - val_loss: 4.7650e-05\n",
            "Epoch 152/200\n",
            "42/42 - 0s - loss: 1.0395e-04 - val_loss: 2.8306e-04\n",
            "Epoch 153/200\n",
            "42/42 - 0s - loss: 1.9637e-04 - val_loss: 2.4234e-04\n",
            "Epoch 154/200\n",
            "42/42 - 0s - loss: 1.3475e-04 - val_loss: 8.3818e-05\n",
            "Epoch 155/200\n",
            "42/42 - 0s - loss: 6.7321e-05 - val_loss: 9.7871e-05\n",
            "Epoch 156/200\n",
            "42/42 - 0s - loss: 6.1190e-05 - val_loss: 8.8930e-05\n",
            "Epoch 157/200\n",
            "42/42 - 0s - loss: 3.4236e-05 - val_loss: 6.5375e-05\n",
            "Epoch 158/200\n",
            "42/42 - 0s - loss: 3.6009e-05 - val_loss: 5.7714e-05\n",
            "Epoch 159/200\n",
            "42/42 - 0s - loss: 9.9055e-05 - val_loss: 1.9989e-04\n",
            "Epoch 160/200\n",
            "42/42 - 0s - loss: 1.8376e-04 - val_loss: 1.3024e-04\n",
            "Epoch 161/200\n",
            "42/42 - 0s - loss: 9.8176e-05 - val_loss: 8.5231e-05\n",
            "Epoch 162/200\n",
            "42/42 - 0s - loss: 5.4319e-05 - val_loss: 7.1251e-05\n",
            "Epoch 163/200\n",
            "42/42 - 0s - loss: 4.0381e-05 - val_loss: 4.3104e-05\n",
            "Epoch 164/200\n",
            "42/42 - 0s - loss: 5.5006e-05 - val_loss: 1.4544e-04\n",
            "Epoch 165/200\n",
            "42/42 - 0s - loss: 1.6231e-04 - val_loss: 1.9146e-04\n",
            "Epoch 166/200\n",
            "42/42 - 0s - loss: 8.0497e-04 - val_loss: 2.5312e-04\n",
            "Epoch 167/200\n",
            "42/42 - 0s - loss: 1.0480e-04 - val_loss: 1.5578e-04\n",
            "Epoch 168/200\n",
            "42/42 - 0s - loss: 8.2150e-05 - val_loss: 5.2325e-05\n",
            "Epoch 169/200\n",
            "42/42 - 0s - loss: 3.4558e-05 - val_loss: 4.3402e-05\n",
            "Epoch 170/200\n",
            "42/42 - 0s - loss: 2.1973e-05 - val_loss: 2.7831e-05\n",
            "Epoch 171/200\n",
            "42/42 - 0s - loss: 4.5065e-05 - val_loss: 1.0466e-04\n",
            "Epoch 172/200\n",
            "42/42 - 0s - loss: 5.4696e-05 - val_loss: 4.1352e-05\n",
            "Epoch 173/200\n",
            "42/42 - 0s - loss: 3.2661e-05 - val_loss: 5.6228e-05\n",
            "Epoch 174/200\n",
            "42/42 - 0s - loss: 3.0377e-05 - val_loss: 6.4645e-05\n",
            "Epoch 175/200\n",
            "42/42 - 0s - loss: 3.7444e-05 - val_loss: 4.0632e-05\n",
            "Epoch 176/200\n",
            "42/42 - 0s - loss: 2.4802e-05 - val_loss: 3.4974e-05\n",
            "Epoch 177/200\n",
            "42/42 - 0s - loss: 2.3259e-05 - val_loss: 2.8508e-05\n",
            "Epoch 178/200\n",
            "42/42 - 0s - loss: 1.1875e-05 - val_loss: 2.1967e-05\n",
            "Epoch 179/200\n",
            "42/42 - 0s - loss: 1.8168e-05 - val_loss: 8.4886e-05\n",
            "Epoch 180/200\n",
            "42/42 - 0s - loss: 6.0833e-05 - val_loss: 3.7265e-05\n",
            "Epoch 181/200\n",
            "42/42 - 0s - loss: 5.7682e-05 - val_loss: 1.0707e-04\n",
            "Epoch 182/200\n",
            "42/42 - 0s - loss: 3.2815e-05 - val_loss: 4.1224e-05\n",
            "Epoch 183/200\n",
            "42/42 - 0s - loss: 3.2400e-05 - val_loss: 6.9069e-05\n",
            "Epoch 184/200\n",
            "42/42 - 0s - loss: 5.9780e-05 - val_loss: 1.6313e-04\n",
            "Epoch 185/200\n",
            "42/42 - 0s - loss: 7.1928e-05 - val_loss: 4.7227e-05\n",
            "Epoch 186/200\n",
            "42/42 - 0s - loss: 5.3697e-05 - val_loss: 8.2803e-05\n",
            "Epoch 187/200\n",
            "42/42 - 0s - loss: 8.2542e-05 - val_loss: 6.9977e-05\n",
            "Epoch 188/200\n",
            "42/42 - 0s - loss: 4.5106e-05 - val_loss: 4.2214e-05\n",
            "Epoch 189/200\n",
            "42/42 - 0s - loss: 3.1995e-05 - val_loss: 4.7667e-05\n",
            "Epoch 190/200\n",
            "42/42 - 0s - loss: 4.9188e-05 - val_loss: 5.1803e-05\n",
            "Epoch 191/200\n",
            "42/42 - 0s - loss: 9.8651e-05 - val_loss: 1.5453e-04\n",
            "Epoch 192/200\n",
            "42/42 - 0s - loss: 2.0222e-04 - val_loss: 1.0971e-04\n",
            "Epoch 193/200\n",
            "42/42 - 0s - loss: 1.1544e-04 - val_loss: 1.1959e-04\n",
            "Epoch 194/200\n",
            "42/42 - 0s - loss: 9.6344e-05 - val_loss: 8.6378e-05\n",
            "Epoch 195/200\n",
            "42/42 - 0s - loss: 8.8391e-05 - val_loss: 6.5969e-05\n",
            "Epoch 196/200\n",
            "42/42 - 0s - loss: 4.9985e-05 - val_loss: 5.6433e-05\n",
            "Epoch 197/200\n",
            "42/42 - 0s - loss: 6.7630e-05 - val_loss: 8.9419e-05\n",
            "Epoch 198/200\n",
            "42/42 - 0s - loss: 1.0698e-04 - val_loss: 1.1401e-04\n",
            "Epoch 199/200\n",
            "42/42 - 0s - loss: 6.5977e-05 - val_loss: 6.3799e-05\n",
            "Epoch 200/200\n",
            "42/42 - 0s - loss: 3.9570e-05 - val_loss: 4.7828e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}